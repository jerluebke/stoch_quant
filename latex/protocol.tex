\documentclass[11pt,a4paper]{scrartcl}
\usepackage{fontspec}
\usepackage{polyglossia}
    \setdefaultlanguage{english}
\usepackage{lmodern}
\usepackage{fixcmex}
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{siunitx}
    \sisetup{%
        range-units=brackets,
        separate-uncertainty=true,
    }
\usepackage{physics}
\usepackage{array}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{graphicx}
    \graphicspath{figures}
\usepackage{tikz}
    \usetikzlibrary{calc,external}
    \tikzexternalize[prefix=extern/]
    \tikzexternaldisable
\usepackage{pgfplots}
    \pgfplotsset{%
        compat=1.15,
        table/search path={data},
    }
\usepackage[makeroom]{cancel}
\usepackage{todonotes}
\usepackage[parfill]{parskip}
\usepackage[%
    colorlinks=true, linkcolor=blue,
    % hidelinks
]{hyperref}
\usepackage{cleveref}


\newcommand*{\figref}[1]{(see fig.~\ref{#1})}
\newcommand{\eg}{e.\,g.}
\newcommand{\ie}{i.\,e.}
\newcommand{\action}{\ensuremath{\mathcal{S}}}
\newcommand{\SD}{\ensuremath{\mathcal{S}_{\mathrm{D}}}}
\newcommand{\xdoti}{\ensuremath{\dot{x}_i}}
\newcommand{\xdotj}{\ensuremath{\dot{x}_j}}
\newcommand{\xdotjm}{\ensuremath{\dot{x}_{j-1}}}
\newcommand{\deltaij}{\ensuremath{\delta_{ij}}}
\newcommand{\OverDeltaT}[1]{\ensuremath{\frac{#1}{\Delta t}}}
\newcommand{\DT}{\ensuremath{\mathrm{D}_t}}
\newcommand{\OverTwoDeltaT}[1]{\ensuremath{\frac{#1}{2\, \Delta t}}}
\newcommand{\xdotjp}{\ensuremath{\dot{x}_{j+1}}}
\newcommand{\avg}[1]{\langle#1\rangle}
\newcommand{\SE}{\ensuremath{\mathcal{S}_{\mathrm{E}}}}
\newcommand{\SED}{\ensuremath{\mathcal{S}_{\mathrm{E,D}}}}
\newcommand{\SEh}{\mathcal{S}_{\mathrm{E},h}}
\newcommand{\pathinth}[1]{\int\mathcal{D}[x]#1e^{-\SEh}}
\newcommand{\pathint}[1]{\int\mathcal{D}[x]#1e^{-\SE}}
\newcommand{\BigO}[1]{\mathcal{O}\left(#1\right)}
\newcommand{\tE}{\ensuremath{t_{\mathrm{E}}}}
\newcommand{\nReals}{\ensuremath{\mathbb{R}^N}}
\DeclareMathOperator{\cov}{cov}


\title{Extensions to the \emph{Stochastic Quantization Manual}}
\author{Jeremiah LÃ¼bke, Franz Wilfarth}
\date{\today}


\begin{document}

\maketitle

\section*{1.1 From Stochastic to Quantum Systems}
The two equations giving a proper description of the desired fictitious
stochastic system are the Langevin and the corresponding Fokker-Planck equation
\todo{add reference}(A.18), which shall be given in the form needed for the
simulation
\begin{subequations}
\begin{align}
    \dv{x_i}{\tau}&=A_i+\zeta_i \\
    \pdv{p}{\tau}&=-\OverDeltaT{1}\pdv{(A_i\,p)}{x_i}+\frac{1}{(\Delta{t})^2}\pdv[2]{p}{x_i}
    \\
    \langle\zeta_i(\tau)\,\zeta_j(\tau')\rangle&=2\OverDeltaT{\deltaij}\delta(\tau-\tau')
\end{align}
\label{eq:stochsys}
\end{subequations}
with $\mathbf{A}\in\nReals$, the Gaussian noise $\mathbf{\zeta}\in\nReals$ and
the dynamical variable $\mathbf{x}\in\nReals$.
Those vectors are to be understood as $n$ sample points from the discrete time
$t$ with
\begin{equation*}
    x_i(\tau)=x(\tau,t_i)\qc\Delta{t}=t_{i+1}-t_i\qc i=1,\dotsc,N
\end{equation*}

A stationary solution ($\partial_{\tau}p=0$) implies
\begin{equation}
    A_i\,p\,\Delta{t}=\partial_i{p}+\mathrm{const.}
    \label{eq:stationaryp}
\end{equation}
where the constant is set to zero to ensure proper decay of $p$ in the infinite
limit. Now let $\mathbf{A}$ be derived from some potential $U(\mathbf{x})$ via
$A_i\,\Delta{t}=-\partial_i{U}$ which immediately results in a solution of
the form
\begin{equation}
    p=c\,e^{-U(\mathbf{x})}
\end{equation}

In analogy to the derivation of the path integral, one takes the limit from the
(finite dimensional) discretization of the time $t$ to a (infinite dimensional)
continuous description via
\begin{gather*}
    \Delta{t}\to0\qc N\to\infty \\
    x_i(\tau)\to x(\tau,t)
\end{gather*}
Then the system of ODEs in eq.~\eqref{eq:stochsys} becomes a partial differential
equation holding for all $t$. Additionally, one has to take into account that
the partial derivatives translate into a functional derivative via \todo{add
citation}[Kis00]:
\begin{equation}
    \lim_{\Delta{t}\to0}\OverDeltaT{1}\pdv{\,\cdot}{x_i}=\fdv{\,\cdot}{x}
    \label{eq:DiscreteFunctionalDerivative}
\end{equation}

Moreover it is important to adequately translate the correlation properly. In
order for the Kronecker Delta \deltaij~to become a Delta function, one has to
normalize them via $\deltaij/\Delta{t}$:
\begin{equation}
    \sum_{i=1}^{N}\OverDeltaT{\deltaij}\Delta{t}=1\to\int\dd{t}\delta(t-t')=1\qc\forall{j,t'}
\end{equation}
The correlation condition for the noise then becomes
\begin{equation}
    \langle\zeta(\tau,t)\,\zeta(\tau',t')\rangle=2\,\delta(t-t')\,\delta(\tau-\tau')
\end{equation}

Finally a new Langevin equation can be formulated with the potential
$U(x)=\SE[x]$
\begin{equation}
    \pdv{x(\tau,t)}{\tau}=-\eval{\fdv{\SE[x]}{x}}_{x=x(\tau,t)}+\zeta(\tau,t)
    \label{eq:SQMLangevin}
\end{equation}
and the corresponding functional Fokker-Planck equation is given by
\begin{equation}
    \pdv{p}{\tau}=-\fdv{x}\left[\left(-\fdv{\SE}{x}\right)p\right]+\fdv[2]{p}{x}
\end{equation}
with the stationary solution
\begin{equation}
    p\propto{e^{-\SE}}
\end{equation}

Now, how does one compute quantum mechanical expectation values? \ldots


\subsubsection*{1.2.1 Parabolic Potential}
\dots

The harmonic oscillator is described by the Euclidean action
\begin{align}
    \action_\mathrm{E}\left[x(t)\right] =
    \int\dd{t_\mathrm{E}}\left[\frac{m}{2}\dot{x}^2 +
        \frac{1}{2}\,m\,\omega^2\,x^2\right]
\end{align}
with $x$ being $x = x(t, \tau )$ and the dot denoting the derivative with
respect to $t_\mathrm{E}$ (for more details, \todo{link appears when using
\texttt{section} instead of \texttt{section*}}see~\ref{app:derivSE}).

\dots


\section*{2 Numerical Approach and Discretization for 1-dimensional Quantum
Mechanics}
The key aspect for the SQM to succeed is the numeric implementation. Therefore
consider the discretization of eq.~\eqref{eq:SQMLangevin} in both Euclidean
time $t$ and fictitious time $\tau$. For the functional derivative remember
eq.~\eqref{eq:DiscreteFunctionalDerivative} for a finite $\Delta{t}$, which
yields together with eqs.~\eqref{eq:EuclideanEulerLagrange},
\eqref{eq:DiscreteActionDerivative}:
\begin{equation}
    \frac{x_l^{i+1}-x_l^i}{\Delta\tau}=m\frac{x_{l+1}^i-2\,x_l^i+x_{l-1}^i}{\left(\Delta{t}\right)^2}-\pdv{V(x_l^i)}{x_l^i}+\sqrt{\frac{2}{\Delta{t}\,\Delta\tau}}\,R_l^i
    \label{eq:DiscreteLangevin}
\end{equation}
with $x_l^i=x(\tau_i,t_l)$ where $l$ denotes the grid in $t$ with spacing
$\Delta{t}$ and $i$ the grid in $\tau$.

The noise is generated from $R^i_l\in\mathcal{N}(0,1)$, which fulfills
$\langle{R^i_l}\,{R^j_m}\rangle=\delta_{ij}\,\delta_{lm}$. In order to fulfill
the correlation condition
\begin{equation*}
    \langle\zeta(\tau,t)\,\zeta(\tau',t')\rangle=2\,\delta(\tau-\tau')\,\delta(t-t')
    \xrightarrow{\mathrm{discrete}}
    \langle\zeta^i_l\,\zeta^j_m\rangle=2\,\frac{\delta_{lm}}{\Delta\tau}\,\frac{\delta_{ij}}{\Delta{t}}
\end{equation*}
which is needed to obtain the correct equilibrium probability distribution, an
additional prefactor is introduced, yielding
$\zeta^i_l=\sqrt{\frac{2}{\Delta{\tau}\Delta{t}}}\,R^i_l$.

Expectation values become \ldots

\dots

The equivalence of those expressions can be easily verified by calculating the
derivative
\begin{align*}
    \eval{\dv{\avg{x_l}_h}{h}}_{h=0} &=
    \eval{\dv{h}\frac{\pathinth{\,x_l\,}}{\pathinth{}}}_{h=0} \\ &=
    \eval{\frac{\left(\pathinth{\,x_l x_0\,}\right)\left(\pathinth{}\right)
    -\left(\pathinth{x_l}\right)\left(\pathinth{x_0}\right)}
    {\left(\pathinth{}\right)^2}}_{h=0} \\ &=
    \frac{\left(\pathint{\,x_0 x_l\,}\right)\left(\pathint{}\right)
    -\left(\pathint{x_l}\right)\left(\pathint{x_0}\right)}
    {\left(\pathint{}\right)^2} \\ &=
    \avg{x_0 x_l}-\avg{x_0}\avg{x_l} \tag{i}\label{eq:i}
\end{align*}
Note the Taylor expansion at $h=0$ (where $\avg{x_l}_0\equiv\avg{x_l}$):
\begin{equation*}
    \avg{x_l}_h=\avg{x_l}_0+\eval{\dv{\avg{x_l}_h}{h}}_{h=0}\,h+\BigO{h^2}
    \tag{ii}\label{eq:ii}
\end{equation*}
Combining equation (\ref{eq:i}) and (\ref{eq:ii}) yields above expression.

\dots


\section*{4 Results}
\subsection*{4.3 Problems with the double-well potential}
When attempting to find the first energy gap of the double-well potential
\begin{equation}
    V(x)=h\left(x^2-a^2\right)^2
    \label{eq:double-well}
\end{equation}
where $h$ is the height of the central barrier and $2\,a$ is the distance of the
minima, one finds that the SQM-algorithm converges \emph{very} slowly (we were not
able to obtain meaningful results during our investigation).

Why is that so? At first recall, that the energy gap is computed via
approximating the correlation function\todo{add reference to eq.~1.12 in the manual}
\begin{align*}
    \ev{x_0\,x_t}{0}&=\sum_{n}e^{-(E_n-E_0)\,t}\mel{0}{x_0}{n}\mel{n}{x_0}{0}
    \\&\approx{e^{-\Delta{E_1}\,t}}\abs{\mel{0}{x_0}{1}}^2
\end{align*}
which is only valid for sufficiently large succeeding energy levels, causing
the remaining terms to decay exponentially. However in our case the first two
energy levels lie rather close to each other\footnote{numerically solving the
eigenvalues of the associated Hamiltonian for $m=1$, $h=1$, $a=1$ yields
$\Delta{E_2}\approx0.79$}, invalidating the approximation.

On the other hand -- from a numerical point of view -- the term
\begin{equation*}
    x_l(\tau_{i+1})=x_l(\tau_i)-\pdv{V(x_l)}{x_l}\Delta\tau+\dotsb
\end{equation*}
in the discretized Langevin equation \eqref{eq:DiscreteLangevin}
corresponds to a gradient descent, which means the algorithm samples the
minimum of a given potential to find the lowest energy gap. Now the double-well
potential has two minima, which both need to be sampled sufficiently in order
to account for the splitting of the energy levels. To achieve this, the
simulated trajectory needs to tunnel back and forth through the barrier.

In this context it is interesting to consider the number of transitions and
observe its change for varying heights. This was done by performing a small
fixed number of simulation steps (\textrightarrow~\emph{multistep}) and
computing a short-term average over this span, which exhibits the small
time-scales of the system, in contrast to the regular long-term average. When
plotting the first, one finds that the trajectory behaves much more dynamically
-- \eg~it tunnels between the two minima --, while the latter approaches some
stable limit which lies between the minima. In order to quantify the number of
transitions, a point in the middle of the trajectory was observed and a
counter was incremented whenever its sign changed (\ie~it tunneled)
\figref{fig:avg}.

\begin{figure}[h]
    \centering
    \includegraphics[width=.75\textwidth]{figures/averages}
    \caption{averaged trajectory after $\approx\num{64000}$ steps and
    short-term average over \num{100} steps}
    \label{fig:avg}
\end{figure}

Our measurements were recorded with fixed $a=1$ and $h\in[0.5,16]$; for each
$h$, \num{10000} mutlisteps were performed, each consisting of 100 simulation
steps. This was repeated 16 times with different seeds for \texttt{numpy}'s
PRNG and eventually mean and standard deviation were computed. The obtained
data closely resembles an exponential relation
\begin{equation*}
    N(h)=N_0\,\exp\left(-\frac{h}{\tau}\right)
\end{equation*}
and indeed, when performing a linear regression on
$\log(N_{\mathrm{measured}})$, one finds that it closely follows the linear
relation
\begin{equation*}
    \log\left(N(h)\right)=m\,h+b
\end{equation*}
with $m=-\tau^{-1}$ and $b=\log{N_0}$ \figref{fig:transitions}. Via error
propagation, one finds
$\tau=\num{3.58(4)}$.

\begin{figure}[h]
    \centering
    \includegraphics[width=.75\textwidth]{figures/transitions}
    \caption{Decay of the tunneling events with increasing height of the potential's barrier}
    \label{fig:transitions}
\end{figure}

This clearly shows, that the number of transitions decreases exponentially with
increasing $h$, and therewith requiring much more simulation steps to obtain
meaningful results.


\section*{5 Conclusion and Outlook}
\dots

Having understood the basics and technicalities of SQM for these
examples, the next interesting step would be the double-well potential
$V(x)=h\left(x^2-a^2\right)^2$.
However, when trying to apply SQM directly to compute the first energy gap of
this potential, one quickly finds this task to be non-trivial, since it
requires a huge amount of simulation steps in order account for the splitting
of the lowest energy levels by sufficiently sampling both minima. This requires
a sufficient number of transitions, which exponentially decreases for
increasing heights $h$, in turn requiring even more simulation steps for
meaningful results. In this situation the advantage of the Parisi trick
vanishes and one needs to think of a more clever way to address this problem.

An alternative way could be provided by doing stochastic quantization
\enquote{around} the fluctuating instantons in the double well (see \todo{add
reference}[MY86]). In general \dots




\section*{C On the functional derivative of the action \action}
\subsection*{C.1 The euclidean action \SE}
\label{app:derivSE}
Assume the Lagrangian to be $L(x,\dot{x})=\frac{m}{2} \dot{x}^2-V(x)$. So the
action $\action$ can be written as:
\begin{align}
    \action\left[x(t)\right] = \int\limits_{t_0}^{t_1}\dd{t}L\left(x(t), \dot{x}(t)\right) = \int\limits_{t_0}^{t_1}\dd{t}\left[\frac{m}{2}\dot{x}^2-V(x)\right]\label{eq:S}
\end{align}
Note that by Wick rotation $t\longrightarrow \tE:=it$. Now $L(x,\dot{x})$ is
dependent on \tE.
\begin{align}
    \action\longrightarrow\SE:=-i\action
    &=\int\dd{\tE}L_\mathrm{E}\left(x(t_\mathrm{E}),
    \dot{x}(t_\mathrm{E})\right) \nonumber \\
    &=-i\int\dd\frac{\tE}{i}\left[\frac{m}{2}\left(\pdv{x}{(\tE/i)}\right)^2-V(x)\right]
    \nonumber \\
    &=-\int\dd\tE\left[-\frac{m}{2}\left(\pdv{x}{\tE}\right)^2-V(x)\right]
    \nonumber \\
    &=\int\dd\tE\left[\frac{m}{2}\dot{x}^2+V(x)\right] \label{eq:SE}
\end{align}

By comparison of \cref{eq:S} and \cref{eq:SE} it can be seen that the
Lagrangian of the Wick rotated action has a different sign in front of it's
potential, resulting in the following Euler-Lagrange-Equation:
\begin{equation}
    \boxed{\fdv{\SE}{x}=\pdv{L}{x}-\dv{\tE}\pdv{L}{\dot{x}}=-m\ddot{x}+\pdv{V}{x}}
    \label{eq:EuclideanEulerLagrange}
\end{equation}


\subsection*{C.2 Discrete functional derivative}
\label{app:deriv-discrete}
In order to show the correspondence between the continuous functional
derivative and its application in a discrete framework, the derivative of the
discretized action is computed.

Let us start with discretizing the functional:
\begin{equation}
    \mathcal{S}\left[x(t)\right] = \int\dd{t}L\left(x(t), \dot{x}(t)\right)
    \quad\longrightarrow\quad
    \SD\left(\{x_i\}\right) = \sum_i L\left(x_i, \xdoti\right)\Delta t
\end{equation}
where $x(t) \longrightarrow x_i = x(t_i)$ and $\dot{x}(t) \longrightarrow
\xdoti = \OverTwoDeltaT{x_{i+1}-x_{i-1}}$. For convenience we write $L_i = L(x_i, \xdoti)$.

We compute the derivative:
\begin{equation}
    \OverDeltaT{1}\dv{\SD}{x_j} =\sum_i\dv{L_i}{x_j}
    =\sum_i\left(\pdv{L_i}{x_i}\pdv{x_i}{x_j}+\pdv{L_i}{\xdoti}\pdv{\xdoti}{x_j}\right)
\end{equation}
with
\begin{subequations}
\begin{gather}
    \pdv{x_i}{x_j}=\deltaij \\
    \pdv{\xdoti}{x_j}=\pdv{\OverTwoDeltaT{x_{i+1}-x_{i-1}}}{x_j}
    =\OverTwoDeltaT{1}\left(\pdv{x_{i+1}}{x_j}-\pdv{x_{i-1}}{x_j}\right)
    =\frac{\delta_{i+1,j}-\delta_{i-1,j}}{2\,\Delta t}.
\end{gather}
\end{subequations}

The Kronecker $\delta$-s kill the sum, and we can write (pay attention to the indices):
\begin{align*}
    \OverDeltaT{1}\dv{\SD}{x_j}&=\pdv{L_j}{x_j}+\frac{1}{2\,\Delta{t}}
    \left(\pdv{L_{j-1}}{\xdotjm}-\pdv{L_{j+1}}{\xdotjp}\right)
    \\
    &=\pdv{L_j}{x_j}-\OverTwoDeltaT{1}\left(\pdv{L_{j+1}}{\xdotjp}-\pdv{L_{j-1}}{\xdotjm}\right)
\end{align*}
\begin{equation}
    \implies\boxed{\OverDeltaT{1}\dv{\SD}{x_j}=\pdv{L_j}{x_j}-\DT\left(\pdv{L_{j}}{\xdotj}\right)}
    \label{eq:DiscreteActionDerivative}
\end{equation}
where $\DT(f_i)=\OverTwoDeltaT{f_{i+1}-f_{i-1}}$ is the discrete time derivation
operator.
This is exactly what we wanted to achieve.

For clarity, we make the transition back to the continuous description:
\begin{equation}
    \lim_{\Delta{t}\to0}\OverDeltaT{1}\dv{\SD}{x_j}
    =\fdv{\mathcal{S}}{x}=\pdv{L}{x}-\dv{t}\pdv{L}{\dot{x}}
\end{equation}
which is the well known \emph{Euler-Lagrange-Equation}.


\end{document}

% vim: set ff=unix tw=79 sw=4 ts=4 et ic ai :
